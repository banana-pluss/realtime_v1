\# 										数据的倾斜



## 数据倾斜的原因

​	1.空值引发的数据倾斜

​	2.不同数据类型引发的数据倾斜

​	3.不可拆分大文件引发的数据倾斜

​	4.表连接时引发的数据倾斜

​	5.聚合类group by操作，发生数据倾斜

## 数据倾斜的概括

​		数据倾斜在MapReduce编程模型中十分常见,用最通俗易懂的话来说,数据倾斜无非就是大量的相同key被partition分配到一个分区里,造成了'一个人累死,其他人闲死'的情况,这种情况是我们不能接受的,这也违背了并行计算的初衷,首先一个节点要承受着巨大的压力,而其他节点计算完毕后要一直等待这个忙碌的节点,也拖累了整体的计算时间,可以说效率是十分低下的。



## 数据倾斜的影响

- **绝大多数任务执行的很快，但个别Executor执行时间很长，导致整体任务卡在某一阶段不能结束以及资源浪费，整体执行时间过长；**
- **原本能够正常执行的Spark作业，爆出内存溢出异常，无法正常产出数据；**
- **个别Reduce处理的数据量与平均数据量相比差异过大，通常可达6倍甚至更多，远远超过其他正常reduce,**



## 解决方法

​			1.将在地区后边加上随机数,将原先一样的地区打散成不同的"地区",这样就可以将处理后的数据分散到不同的test中去运行,而不是让让一个test去处理大量相同的数据

```sql
with t1 as (
    select userid,
           order_no,
           concat(region,'-',rand()) as region,
           product_no,
           color_no,
           sale_amount,
           ts
    from date_east
),
    t2 as (
        select region,
               count(1) as cnt
        from t1
        group by region
    ),
    t3 as (
        select region,
               substr(region,1,2) as re,
               cnt
        from t2
    )
select re,
       count(1) as cnt
from t3
group by re;
```

​			2.还可以增加reduce去优化数据倾斜(不适合大量数据)

```
500000000即（500M）
set hive.exec.reducers.bytes.per.reducer=500000000; 
set mapred.reduce.tasks = 15;
```

​		3.spark aqe

​			1 Join的自适应[数据倾斜](https://so.csdn.net/so/search?q=数据倾斜&spm=1001.2101.3001.7020)处理

## 总结

​		为了减少代码的运行时间,资源浪费以及内存溢出