# 实时数仓的逐字稿

面试官你好, 我叫马振波 目前已经有五年大数据开发经验,流批一体,线上产品是对阿里的dataworks和线下产品CDH
一个从0到1的搭建 ,线下集群 CDP CDP 都有能独立完成的搭建部署压测调优上线
开发语言主要使用的是Java 和python
java主要用于写一写些finksql 和做一些 实时的
python主要用于数据爬虫 数据的脱敏和清洗等
以上就是我的一个简单的自我介绍 谢谢面试官

* 数据仓库是一个为数据分析而设计的企业级数据管理系统。数据仓库可集中、整合多个信息源的大量数据，借助数据仓库的分析能力，企业可从数据中获得宝贵的信息进而改进决策。

* 主体架构是:DIM, DWD, DWS

### DIM(维度关联)

* DIM层的设计依据是维度建模理论,该层存储维度模型的维度表
* 使用广播流将配置表广播出去然后与维度表进行关联,储存到HBase中
* 我们一般使用K-V的类型进行储存,常见的有Redis、HBase,而Redis常驻于内存中,大量的数据会给内存造成压力还有可能会丢失数据,因此选择HBase,HBase是先写入日志再写入数据,HBase是储存到HMaster

### DWD(维度建模)

* DWD层的设计依据是维度建模理论,该层存储维度模型的事实表
* 主要是对数据进行一个清洗过滤:对流中数据进行解析，将字符串转换为JSONObject，如果解析报错则必然为脏数据。定义侧输出流，将脏数据发送到侧输出流，写入Kafka脏数据主题

#### 1.新老访客

* ①.如果is_new的值为1
* 如果键控状态为null，认为本次是该访客首次访问 APP，将日志中 ts 对应的日期更新到状态中，不对 is_new 字段做修改；
* 如果键控状态不为null，且首次访问日期不是当日，说明访问的是老访客，将 is_new 字段置为 0；
* 如果键控状态不为 null，且首次访问日期是当日，说明访问的是新访客，不做操作；


* ② 如果 is_new 的值为 0
* 如果键控状态为 null，说明访问 APP 的是老访客但本次是该访客的页面日志首次进入程序。当前端新老访客状态标记丢失时，日志进入程序被判定为新访客，Flink
  程序就可以纠正被误判的访客状态标记，只要将状态中的日期设置为今天之前即可。本程序选择将状态更新为昨日；
* 如果键控状态不为 null，说明程序已经维护了首次访问日期，不做操作。

# dws(指标)

#### 1. 流量域搜索关键词粒度页面浏览各窗口汇总表

* 使用分词工具将关键词拆分成多个词，返回一个 List 集合。
* 根据拆分的关键词进行分组,然后开窗聚合,求出页面浏览量存入Doris

#### 2. 流量域版本-渠道-地区-访客类别粒度页面浏览各窗口汇总表

* 读取页面主题,根据设备ID分组,
* 统计页面浏览时长、页面浏览数、会话数和独立访客，转换数据结构然后按照维度字段进行分组开窗聚合

#### 3. 流量域首页、详情页页面浏览各窗口汇总表

* 过滤数据 仅保留 page_id 为 home 或 good_detail 的数据
* 按照 mid 分组 统计首页和商品详情页独立访客数，转换数据结构
* 如果 page_id 为 home，当状态中存储的日期为 null 或不是当日时，将 homeUvCt（首页独立访客数） 置为 1，并将状态中的日期更新为当日。否则置为
  0

#### 4. 用户域用户登录各窗口汇总表

* 统计七日回流用户和当日独立用户数
* 之前的活跃用户，一段时间未活跃（流失），今日又活跃了，就称为回流用户
* 我们应保留 uid 不为 null 且 last_page_id 为 null 或 last_page_id 为 login 的浏览记录。

#### 5. 用户域用户注册各窗口汇总表

* 从dwd读注册表即可,然后开窗聚合统计注册数

#### 6. 交易域加购各窗口汇总表

* 读取明细表,统计各窗口加购独立用户数
* 根据用户ID分组,然后过滤加购日期不等于null或者是当前日期的然后进行开窗聚合找出大于等于二的

#### 7. 交易域支付成功各窗口汇总表

* 从Kafka读取交易域支付成功主题数据，统计支付成功独立用户数和首次支付成功用户数。
* 按照user_id进行分组 找出末次支付为零的,则是首次支付成功用户数,找出末次支付为当前日期的则是独立用户数

#### 8. 易域下单各窗口汇总表

* 从 Kafka订单明细主题读取数据，统计当日下单独立用户数和首次下单用户数，封装为实体类，写入Doris。
* 按照user_id进行分组 找出末次下单为零的,则是首次下单成功用户数,找出末次下单为当前日期的则是独立用户数

#### 9. 交易域SKU粒度下单各窗口汇总表

* 过滤null数据并按照唯一键对数据去重，按照SKU维度分组，统计原始金额、活动减免金额、优惠券减免金额和订单金额，并关联维度信息，将数据写入Doris交易域SKU粒度下单各窗口汇总表
  *按照 user_id 分组
* 按照维度信息分组，度量字段求和，并在窗口闭合后补充窗口起始时间和结束时间。将时间戳置为当前系统时间。
* （1）关联 sku_info 表
  获取 sku_name，tm_id，category3_id，spu_id
* （2）关联 spu_info 表
  获取 spu_name。
* （3）关联 base_trademark 表
  获取 tm_name。
* （4）关联 base_category3 表
  获取 name（三级品类名称），获取 category2_id。
* （5）关联 base_categroy2 表
  获取 name（二级品类名称），category1_id。
* （6）关联 base_category1 表
  获取 name（一级品类名称）。

#### 10. 交易域SKU粒度下单各窗口汇总表

* 从 Kafka 读取退单明细数据，关联与分组相关的维度信息后分组，统计各分组各窗口的订单数和订单金额，补充与分组无关的维度信息，将数据写入
  Doris 交易域品牌-品类-用户粒度退单各窗口汇总表
* （1）关联sku_info表
* （2）获取tm_id，category3_id。
* 按照维度信息分组，度量字段求和
* （1）关联base_trademark表
  获取tm_name。
* （2）关联base_category3表
  获取name（三级品类名称），获取category2_id。
* （3）关联base_categroy2表
  获取name（二级品类名称），category1_id。
* （4）关联base_category1 表 获取name（一级品类名称）。

最后使用内网穿透上大屏但是统计的指标


